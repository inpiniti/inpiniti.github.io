---
title: 040203 Multiple Processes and Systems
author: JUNG YoungKyun
date: 2023-04-10
category: 37 celonis
layout: post
---

위 벳지는 수강을 완료하고 받은 뱃지입니다.

# Get Data into the EMS

![](https://d3i9g4671ronu3.cloudfront.net/thoughtindustries-eu/image/upload/q_100,a_exif,c_crop,x_0,y_0,w_800,h_450/a_exif,c_fill,w_800,h_450/v1/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/e2jaa6l2jb4l-course_Get-Data-into-EMS_detail.jpg)

# 02. Refine your Data Pipeline

# Multiple Processes and Systems

![](https://d3i9g4671ronu3.cloudfront.net/thoughtindustries-eu/image/upload/a_exif,c_fit,w_440,h_200/v1/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/u11u85shvtxd-skill-area_Hiring_catalogue.jpg)

## 1 소개

### 11 학습 목표

- 여러 데이터 `연결이 있는 데이터 모델 설정`
- 여러 프로세스로 데이터 모델 설정
- 데이터 모델에 `이벤트 로그 병합`
- 데이터 풀 옵션으로 효과적으로 작업하여 작업을 `확장하고` 보호하십시오.

## 2 여러 시스템 연결

### 21 하나의 프로세스를 위한 여러 시스템

#### 211 병렬 대 순차 시나리오

종단 간 프로세스를 위한 데이터 모델을 구축할 때 `종종 여러 시스템에서 데이터를 가져와야 합`니다.

여기서 두 가지 주요 시나리오가 발생합니다.

먼저 `병렬 또는 수평` 시나리오가 있습니다 . 
이 시나리오에서는 정확히 동일한 프로세스가 서로 다른 시스템에서 병렬로 실행됩니다 . 
서로 다른 국가에 지사를 두고 있는 회사는 사업을 운영하는 각 국가 별로 전용 소스 시스템을 보유하고 있기 때문에 
이에 대한 완벽한 예입니다 .

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/ew1srilg792d-image.png)

그런 다음 `순차 또는 수직` 시나리오가 있습니다 . 
"순차적"은 프로세스의 다른 단계가 다른 소스 시스템에서 추적된다는 사실을 나타냅니다. 
예를 들어, “Activity A”에 대한 정보는 “Source system 1”에 저장되고 
“Activity D”에 대한 정보는 “Source System 3”에 저장됩니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/yy29w4qtui7e-image.png)

두 시나리오의 혼합이 가능하고 일반적입니다. 하지만 지금은 각 시나리오를 개별적으로 처리하는 방법을 살펴보겠습니다.

#### 212 병렬(수평) 시나리오 처리

3개의 동일한 시스템이 동일한 프로세스를 처리하는 병렬 시나리오를 처리하려면 
데이터 풀을 생성하고 `3개의 연결을 설정한 다음` 각 `연결에 대해 하나의 데이터 작업을 설정`해야 합니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/qmcz95xlf5gq-image.png)

템플릿 및 매개변수 사용

세 시스템 모두에서 추출이 정확히 `동일한 경우` 세 소스 시스템 모두에 `하나의 추출 템플릿을 재사용할 수 있`습니다. 
일부 매개변수가 통화 또는 타임스탬프와 같이 `약간 다른 경우 템플릿 인스턴스에서 조정할 수 있`습니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/mdnoz6nkf9ty-image.png)

변환에도 동일한 접근 방식이 적용됩니다. `변환 템플릿은 소스 시스템에서 동일할 때마다 사용할 수 있`습니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/703pd2kn8xog-image.png)

글로벌 데이터 작업과 병합

이상적으로는 템플릿만 사용하여 각 소스 시스템 에 대한 추출 및 변환을 만들었으면 
이제 세 개의 활동 테이블 과 모든 원시 데이터 테이블이 세 번 있어야 합니다.

다음 단계는 `이러한 테이블을 병합하는 것`입니다. 여기에서 글로벌 데이터 작업이 시작됩니다.

`글로벌 데이터 작업`은 데이터 풀의 `모든 테이블에 액세스할 수 있`으며 하나의 특정 데이터 연결로 제한되지 않습니다.

전역 작업을 사용하면 `활동 테이블과 다른 테이블을 병합`하여 사례 테이블 및 마스터 데이터 테이블에 대한 
중앙 테이블뿐만 아니라 하나의 중앙 활동 테이블을 가질 수 있습니다.

요약하면 이 예제에서는 `4개의 데이터 작업을 생성`합니다. 
각 소스 시스템에 대한 추출 및 변환 태스크로 구성된 `3개의 작업과` 
생성된 테이블을 병합하기 위한 변환이 포함된 `1개의 글로벌 작업`.

결국 전역 작업에서 결합된 테이블을 포함하는 하나의 데이터 모델을 갖게 됩니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/abmu5qandl6c-image.png)

#### 213 순차(수직) 시나리오 처리

순차적 시나리오를 살펴보겠습니다. 
이 예에서는 프로세스의 서로 다른 단계를 실행하는 구조가 다른 세 가지 소스 시스템이 있습니다. 
`하나의 시스템은 "구매 주문` 항목 생성" 활동에 대한 타임스탬프를 저장할 수 있고 
`다른 시스템은 "도서 송장`" 활동에 대한 타임스탬프를 저장할 수 있습니다. 
병렬 시나리오와 달리 각 시스템에 대해 동일한 추출 및 변환 템플릿을 사용할 수 없습니다. 
따라서 시스템마다 `추출 및 변환이 다른 별도의 데이터 작업을 생성`해야 합니다 .

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/crzn2fzmmcy5-image.png)

데이터 병합을 위한 전역 작업

모든 단일 연결에 대한 추출 및 변환을 작성하고 실행한 후 활동 테이블을 병합하려면 다시 전역 변환이 필요합니다. 
순차 시나리오에서는 원시 데이터 테이블이 동일한 소스 시스템에서 제공되지 않고 
콘텐츠와 구조가 다를 가능성이 높기 때문에 `원시 데이터 테이블을 병합하는 것은 이치에 맞지 않`습니다.

마지막으로 전역 데이터 작업의 병합된 활동 테이블과 
다른 데이터 작업의 별도 원시 데이터 테이블을 포함하는 하나의 데이터 모델을 설정합니다.

#### 214 글로벌 데이터 작업

공통 분모를 찾으셨나요? 예, 글로벌 데이터 작업입니다. 
`데이터 통합에서 글로벌 데이터 작업으로 작업할 수 있는 방법`을 살펴보겠습니다.

EMS의 데이터 구조를 일반 데이터베이스 구조와 비교할 수 있습니다. 
데이터 풀은 별도의 데이터베이스 및 스키마에 대한 데이터베이스 연결에 해당합니다.
 추출되거나 변환된 테이블은 해당 스키마 또는 연결에 저장됩니다.

글로벌 데이터 작업에는 연결된 연결이 없으며 데이터 풀에 별도의 스키마가 생성됩니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/1tb0khv4xbk1-image.png)

`전역 작업은` 소스 시스템에 연결되어 있지 않으므로 `추출 작업을 생성할 수 없으`며 
`변환 및 데이터 모델 로드만 생성`할 수 있습니다 . 
이러한 `변환에서는` 데이터 풀의 다양한 스키마(연결)에서 `모든 데이터에 액세스 할 수 있`습니다 . 
`글로벌 작업에서 새 테이블을 생성하면` 테이블이 `글로벌 스키마에 저장`됩니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/o8970nwj5tkz-image.png)

#### 215 글로벌 데이터 작업 생성

이제 병렬 시나리오를 사용하여 실제로 여러 시스템을 연결하는 방법을 살펴보겠습니다. 
이미 연결된 시스템과 완전히 동일한 구조를 가진 다른 국가의 프로세스 데이터가 포함된 
두 번째 소스 시스템이 있다고 가정합니다 .

첫 번째 단계는 두 번째 소스 시스템을 연결하는 것입니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/74391a16qft9-image.png)

다음으로 `첫 번째 소스 시스템의 기존 추출 및 변환을 템플릿으로 변환`하고 
이를 `두 번째 시스템의 새 데이터 작업에 추가`합니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/ymnz9ela7b4z-image.png)

이제 데이터가 시스템에 나타나도록 두 번째 데이터 작업을 실행할 시간입니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/x0hogm3iay0w-image.png)

완료되면 두 시스템의 테이블을 병합하여 두 시스템의 집계된 데이터로 중앙 테이블을 만들 차례입니다. 
아시다시피 전역 데이터 작업으로 이 작업을 수행할 수 있습니다.

"`새 데이터 작업"을 생성`하고 이름을 `"P2P 데이터 병합"으로 지정`하고 연결을 `글로벌로 진행`합니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/7k98ytdai9iu-image.png)

이제 각각의 테이블을 하나로 묶는 변환을 만들어 봅시다.

가장 좋은 방법은 병합하는 모든 테이블에 대해 변환을 생성하는 것입니다.

활동 테이블부터 시작하여 "활동 테이블 병합"이라는 새 변환 작업을 생성해 보겠습니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/c26l4dk9tyva-image.png)

테이블을 병합하려면 UNION ALL 문을 사용해야 합니다.

활동 테이블의 구조가 완전히 동일하므로 두 테이블에서 `모든 항목을 선택`하고 
`"UNION ALL" 문을 적용`하여 중앙 활동 테이블을 간단히 생성할 수 있습니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/ppch4kujols4-image.png)

이제 변환을 실행하여 중앙 활동 테이블을 생성해 봅시다!

전역 데이터 작업을 완료하려면 모든 추가 원시 데이터 테이블에 대해 유사한 변환 작업을 생성해야 합니다.

다음 단계에서 데이터 모델을 설정할 때 전역 데이터 작업의 중앙/병합 테이블만 포함해야 합니다.

## 3 여러 프로세스 연결

### 31 하나의 시스템에서 관련 없는 프로세스

종종 하나의 소스 시스템은 서로 관련이 없거나 
프로세스 간의 상관 관계를 보고 싶지 않은 여러 프로세스에 대한 정보를 저장합니다.

예를 들어 `매입 대금 데이터`와 `지불 계정 데이터`를 포함하는 데이터베이스가 있을 수 있습니다. 
이 경우 하나의 시스템에 연결하는 하나의 데이터 연결을 포함하는 하나의 데이터 풀을 생성할 수 있습니다. 
데이터 작업의 경우 이 특정 연결에 연결된 하나의 작업을 생성합니다. 
이 작업에서는 두 프로세스에 대한 모든 관련 데이터를 추출할 수 있습니다. 
따라서 `첫 번째 데이터 작업에는 추출` 작업만 포함됩니다.

그런 다음 `변환만 포함하는 데이터 작업을 두 개` 더 만듭니다. 
하나는 `구매-지불` 프로세스에 대한 `활동 테이블`과 `원시 데이터 테이블을 생성` 하고 
다른 하나는 `지불 계정` 프로세스에 대한 `테이블을 생성`합니다 .

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/pu5q5kcshql0-image.png)

이 모범 사례는 데이터 작업을 합리적인 수로 유지하고 생성한 다양한 작업에 대한 좋은 개요를 유지하는 데 도움이 됩니다.

각 프로세스에 대한 별도의 테이블이 있으면 이제 두 개의 개별 데이터 모델을 만들 수 있습니다. 
즉, 추출 작업과 별도로 나머지 작업을 하나의 Data Pool에 별도로 보관할 수 있습니다.

### 32 하나 이상의 시스템에서 관련 프로세스

#### 321 다중 이벤트 로그 개요

`여러 프로세스를 병렬로 분석`하거나 여러 프로세스에 필터를 적용하려면 어떻게 해야 합니까? 
데이터 통합에서 모든 것을 하나의 케이스 키(예: 하나의 프로세스 관점)에 매핑하려고 시도하면 
`복잡한 테이블 조인이 발생할 수 있`으며 다운스트림 분석에서 원하는 투명성을 제공하지 못할 수 있습니다.

관련 프로세스를 함께 가져오거나 여러 반독립 프로세스를 병렬로 분석하는 `복잡성을 줄이기 위해 `
실제로 `하나의 데이터 풀에 여러 활동 및 사례 테이블을 가질 수 있습`니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/jv1gcy0bezqx-image.png)

이를 `다중 이벤트 로그` 또는 다른 말로 다중 활동 테이블이라고 합니다. 
데이터 모델에 둘 이상의 프로세스가 있을 때입니다.

예를 들어, Order-to-Cash 프로세스용 활동 테이블과 P2P 프로세스용 활동 테이블을 생성할 수 있습니다. 
모든 것을 하나의 활동 테이블에 조인하는 대신 `적절한 외래 키를 사용하여 `
데이터 모델의 개별 활동 테이블을 간단히 `연결할 수 있습`니다.

즉, 활동 테이블을 함께 가져오는 글로벌 데이터 작업 이외의 
또 다른 방법(이 경우에는 서로 다른 프로세스에 대해)은 데이터 모델 로드 단계를 사용하는 것입니다.

다중 이벤트 로그는 서로 `다르지만 관련된 프로세스에서 작업`하는 경우에 특히 `적합`합니다.

분석에서 다중 이벤트 로그는 다음과 같이 표시됩니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/lair4djhcc2b-image.png)

사용 사례

`다중 이벤트 로그`의 네 가지 사용 사례는 다음과 같습니다.

1. 독립적인 프로세스를 컨텍스트에 넣기 위해(프로세스 간 필터링).
2. 여러 계층적 이벤트 로그를 `연결하여 병렬 프로세스를 분석`합니다.
3. 이벤트 로그를 병합하여 변환 `스크립트 노력(조인 없음)을 줄이기` 위해.
4. `여러 이벤트 로그를 연결`하여 엔드 투 엔드 프로세스를 시각화합니다.

필요한 경우 병합

`활동 테이블을 별도로 로드하거나 병합할 수 있`습니다. 
데이터 모델의 "Eventlog automerge" 토글은 활동 테이블의 병합을 트리거합니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/nb3xqmmw291n-image.png)

#### 322 여러 활동 및 사례 테이블 정의

데이터 통합에서 간단한 예를 살펴보겠습니다.

변환에서는 여러 활동 테이블을 정의하고 관련 활동으로 채웠다고 가정합니다. 
관리 가능하고 일정을 고려하려면 가능한 경우 프로세스 영역별로 별도의 데이터 작업을 생성하는 것이 가장 좋습니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/ygc0oe6n2euq-image.png)

데이터 연결, 데이터 작업 및 태스크를 설정하는 정확한 방법은 
시스템 아키텍처, 데이터가 상주하는 위치 및 데이터를 가장 잘 결합할 수 있는 방법에 따라 다릅니다. 
최종 결과는 `단순히 하나의 데이터 풀에` `여러 활동 및 사례 테이블을 갖는 것`입니다.

프로세스 데이터 모델에서는 모든 관련 테이블을 하나의 데이터 모델에 추가했습니다. 
여기에서 여러 활동 및 사례 테이블이 정의되고 외래 키로 서로 연결된 것을 볼 수 있습니다. 
이미지의 As 및 Cs는 테이블이 활동인지 사례 테이블인지 나타냅니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/saws5m2kutws-image.png)

기본적으로 정의한 첫 번째 활동 테이블은 기본 활동 테이블 입니다 . 
이것은 분석 또는 보기를 작성할 때 구성 요소에 자동으로 가장 먼저 나타나는 테이블입니다. 
테이블을 활동 테이블 또는 기본 활동 테이블로 설정하거나 
활동 테이블의 사례 테이블을 정의하려면 활동 테이블에서 세로 줄임표(점 3개) 옵션을 사용합니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/yktaa0eyyoc9-image.png)

#### 323 병합하거나 병합하지 않으려면

활동 및 사례 테이블을 정의하고 모든 테이블을 해당 외래 키와 연결했으면 데이터 모델을 로드하는 방법을 고려해야 합니다 .

다중 이벤트 로그의 경우 데이터 모델 로드를 구축할 때 `이벤트 로그 자동 병합 기능을 사용하도록 선택할 수 있`습니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/2ctv24ib0ilv-image.png)

기능

이 병합은 모든 활동 테이블을 가져오고 기본 활동 테이블의 사례 ID에 따라 각각의 타임스탬프별로 정렬하여 
`하나로 가져옵`니다.

예를 들어 Table2가 기본 활동 테이블인 다음 세 가지 테이블 세트를 사용하십시오.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/gztfttiwmc6s-image.png)

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/hop6rcc8bbqu-image.png)

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/xpgdlg76ud96-image.png)

병합하면 다음과 같은 이벤트 로그가 생성됩니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/ecaruwyrvxvg-image.png)

여기서 사례 ID는 모두 조인 경로를 사용하여 Table2의 사례 ID 아래로 가져왔습니다. 
각각의 타임스탬프가 있는 활동이 병합되었습니다. 
각 테이블의 추가 열이 추가되었고 `사용 가능한 값이 없는 경우 null로 남았`습니다.

Eventlog 자동 병합을 사용하면 데이터 모델이 로드된 후 _CEL_MERGED_ACTIVITIES 라는 
병합된 eventlog 테이블을 사용할 수 있습니다. 
분석에서 이 테이블을 다른 이벤트 로그(활동) 테이블로 사용할 수 있습니다.

질문으로 돌아가서, 언제 병합해야 합니까? `하나의 순차 활동 테이블로 작업하려는 경우` 
활동 테이블을 `병합하는 것이 좋습`니다 . 
그렇지 않은 경우 데이터 모델에 별도의 활동 테이블을 유지하는 것이 더 합리적입니다.

PQL에서 병합

Eventlog 자동 병합은 분석에서 MERGE_EVENTLOG `PQL` 연산자를 사용하기 위한 `지름길일` 뿐입니다. 
데이터 통합에서 수행하지 않도록 선택한 경우에도 분석에서 `PQL 연산자를 사용하여 `
이동 중에 활동 테이블(이벤트 로그)을 `병합할 수 있습니다`. 
PQL을 사용하면 유지할 열을 선택할 수 있으므로 병합 시 `유연성이 향상됩`니다.

일부 병합은 결과가 `중복`된다는 점에 유의하십시오. 
이러한 경우 "`merge event log distinct" 옵션을 사용해야 합`니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/0koq1d8dkogb-image.png)

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/pkrukl6dlyhc-image.png)

#### 324 로그 병합과 관련된 일반적인 문제

1. 경고: `이벤트 로그 자동 병합이 활성화되었지만 기본 이벤트 로그가 구성되지 않았습니다. `-> 
이는 단순히 활동 테이블 중 하나를 기본 테이블로 설정해야 함을 의미합니다. 
이 경고와 함께 데이터 모델 로드와 함께 병합된 활동 테이블이 생성되지 않지만 
일반 데이터 로드와 마찬가지로 분석 작업을 계속할 수 있습니다.

2. 오류: `이벤트 로그 자동 병합이 활성화되었지만 이벤트 로그를 기본 이벤트 로그와 병합할 수 없습니다.` -> 
이는 다른 활동 테이블을 찾을 수 없고 데이터 모델에서 기본 활동 테이블에 연결할 수 없음을 의미합니다. 
즉, 적절한 조인 경로가 없습니다.

## 4 데이터 풀 작업

### 41 데이터 풀 작업

#### 411 데이터 풀 옵션

- 데이터 연결 공유
- 데이터 풀 버전 관리
- 데이터 풀 복사
- 데이터 작업 복사

#### 412 데이터 통합 ​​용어 요약

두 가지 추가 고급 용어인 클러스터와 팀을 명확히 해야 합니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/cc1ja4yvykhv-image.png)

- `클러스터` - Realm이라고도 하며 일반적으로 eu-1 또는 us-1과 같은 `호스팅 위치를 반영`합니다. 
훈련 클러스터 와 마찬가지로 특정 목적을 반영할 수도 있습니다 . 
URL "https://data-testing.training .celonis.cloud/"에서 Celonis 환경의 클러스터/영역을 볼 수 있습니다 .

- `팀` - Celonis에서 "팀"은 `환경과 동의어`입니다. 
Celonis Academy에서 교육을 이수하면 교육 클러스터에 생성된 개인 교육 팀을 받게 됩니다.

#### 413 데이터 연결 공유

경우에 따라 데이터 풀에서 동일한 데이터 중 일부를 `재사용하거나` 
데이터 풀의 일부 데이터에 대한 액세스를 제한 해야 합니다. 
여러 데이터 풀에서 동일한 데이터를 `사용할 수 있어야 하는 경우 데이터 전송 옵션을 사용할 수 있습`니다 . 
이를 통해 `동일한 팀 에 있는 하나 이상의 데이터 풀과 데이터 연결을 공유` 할 수 있습니다 .

공유할 때 EMS는 공유 데이터 연결의 테이블에 대한 보기를 만듭니다. 
`뷰는` 단순히 기존 테이블을 참조하고 쿼리하는 가상 테이블입니다. 
이 접근 방식을 사용하면 데이터 풀 간에 데이터가 `복제되지 않습`니다. 
데이터 풀의 일반 연결은 물론 "전역 범위"
(예: 파일 업로드가 기본적으로 이동하는 데이터가 있는 연결과 관련되지 않은 전역 스키마)를 공유할 수 있습니다.

데이터 통합에서 데이터 연결에 있는 세 개의 점을 클릭하여 공유 옵션을 찾을 수 있습니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/4enysm9w3r00-image.png)

그런 다음 공유할 풀을 결정합니다. 
대상 데이터 풀에서 새 연결을 설정하고 "`다른 풀에서 데이터 가져오기"를 선택할 수 있`습니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/ag58lfenlury-image.png)

#### 414 데이터 풀 버전 관리

데이터 풀 버전 관리를 통해 다음을 수행할 수 있습니다.

- 데이터 풀의 변경 사항 추적
- 특정 변경으로 인해 문제가 발생하는 경우 이전 버전으로 되돌리기
- 데이터 풀 버전을 다른 데이터 풀로 쉽게 복사하여 별도의 개발 및 생산 환경

버전이 무엇입니까?

데이터 풀 버전에는 다음이 포함됩니다.

- 데이터 작업,
- 프로세스 데이터 모델,
- 데이터 매개변수,
- 작업 템플릿,
- 및 일정.

그리고 그들은 제외합니다;

- 데이터 권한,
- 데이터 연결 세부 정보,
- 실제 데이터

어디에 있으며 무엇을 할 수 있습니까?

데이터 통합에서 오른쪽 상단 모서리의 "버전"(레이블 아이콘) 아래에서 데이터 풀의 버전을 볼 수 있습니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/hs614t9r3kpt-image.png)

여기에서 다음을 수행할 수 있습니다.

1. 새 버전 저장
2. 다른 버전을 활성 버전으로 로드
3. 버전 삭제
4. 두 버전 비교
5. 동일한 팀 또는 다른 팀의 다른 데이터 풀에 버전을 복사합니다. 팀은 동일한 클러스터에 있어야 합니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/hhgoplsqdb98-image.png)

`버전 관리는 자동이 아닙니다.`

초안을 만들려면 먼저 초안을 저장하고 변경 사항에 대한 `짧은 메모를 작성하고` 
`어떤 종류의 업그레이드인지 표시해야` 합니다. 저장 메뉴는 현재 초안과 새 초안의 차이점을 보여줍니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/fmon2ytge0lm-image.png)

다른 데이터 풀에 버전 복사 버전을 복사할

때 다음을 수행해야 합니다.

- `기존 연결을 매핑`하여 데이터 작업이 적절한 연결에서 작동하는지 확인합니다.
- 데이터 `작업을 일치시켜` 데이터 작업 경고가 대상 데이터 풀에 유지되도록 합니다.
- 대상 데이터 풀에서 `데이터 모델을 일치시킵`니다 . 
대상 데이터 풀의 EMS 개체에 연결된 기존 데이터 모델을 덮어쓰는 경우에 해당됩니다.
- `버전을` 직접 로드할지 또는 단순히 버전으로 추가하되 로드하지 않을지 `결정합`니다.

고맙게도 복사 마법사가 다음 단계를 하나씩 안내합니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/ah3hjeawqr1u-image.png)

동일한 클러스터 에서 액세스 권한이 있는 다른 팀에 버전을 복사할 수 있습니다 .

#### 415 데이터 풀 복사

경우에 따라 전체 데이터 풀을 동일한 팀이나 다른 팀에 복제하려고 할 수 있습니다. 
이렇게 하려면 `데이터 풀로 이동하여 "복사 대상" 옵션을 선택`하고 `복사할 팀을 선택`하기만 하면 됩니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/f5fvxbuhj27y-image.png)

이것은 모든 데이터 풀의 `연결, 작업, 태스크 및 데이터 모델을 복제`합니다. 
동일한 클러스터에서 액세스 권한이 있는 모든 팀에 데이터 풀을 복사할 수 있습니다 .

#### 416 데이터 작업 복사

경우에 따라 모든 스크립트를 재사용하기 위해 한 풀에서 다른 풀로 `데이터 작업을 복사하기만 할 수 있`습니다. 
이를 위해 데이터 작업 수준에서 "복사 대상" 기능을 사용할 수 있습니다.

![](https://d3i9g4671ronu3.cloudfront.net/course-uploads/1cc62825-20df-4077-8216-a9df1132a5ad/4zwc8lzac084-image.png)

동일한 클러스터에서 액세스할 수 있는 모든 팀에 복사할 수 있습니다 . 함수는 다음을 복사합니다.

- 추출
- 변환
- 로컬 매개변수
- 템플릿

다음은 제외됩니다.

- 데이터 풀 매개변수
- 데이터 모델 로드 작업
- 작업 알림
- 테이블과 데이터

추출을 포함한 작업을 글로벌 범위로 복사하면 글로벌 데이터 작업에 추출이 포함될 수 없으므로 추출이 제거됩니다.

#### 417 데이터 자산을 밀고 당기는 다른 가능성

`Pycelonis는` 데이터 풀, 데이터 모델, 데이터 작업 등과 같은 Celonis 개체와 상호 작용하기 위해
 Machine Learning Workbench 내에서 사용할 수 있는 `Python 패키지입니다.`

Machine Learning Workbench에서 사용할 수 있는 또 다른 도구는 Content-CLI 
(Command Line Interface) 도구입니다. 
pycelonis와 유사하게 이를 사용하여 `한 팀에서 다른 팀으로 데이터 및 데이터 자산을 이동할 수 있`습니다.

## 5 과정 요약

- 전역 데이터 작업을 사용하여 병렬 및 순차 시나리오를 모두 처리하는 방법 .
- 다르지만 관련된 프로세스에 대해 여러 활동 및 사례 테이블이 있는 데이터 모델을 만드는 방법 .
- 다중 이벤트 로그의 사용 사례 정보 :
    - 독립적인 프로세스를 컨텍스트에 넣기 위해(프로세스 간 필터링).
    - 여러 계층적 이벤트 로그를 연결하여 병렬 프로세스를 분석합니다.
    - 이벤트 로그를 병합하여 변환 스크립트 노력(조인 없음)을 줄이기 위해.
    - 여러 이벤트 로그를 연결하여 엔드 투 엔드 프로세스를 시각화합니다.
- Eventlog 자동 병합이 작동하고 여러 활동 테이블을 병합하는 방법 .
    - Eventlog 자동 병합으로 데이터 모델을 로드할 때 두 가지 일반적인 문제를 해결하는 방법.
- 다음을 통해 데이터 풀로 작업을 관리하는 방법 :
    - 데이터 연결 공유,
    - 데이터 풀 버전 관리 및 복사,
    - 데이터 작업 복사,
    - 고급 작업을 위해 다른 코드 기반 도구 사용

